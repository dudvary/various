{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258f3d80-674f-453f-bcc9-2ff98ed52131",
   "metadata": {},
   "source": [
    "# Turn series of images into video \n",
    "Jupyter Notebook Script to turn series of photos into a one photo per day video compilation\n",
    "- Resizes photos to 1080p\n",
    "- Add text to photos (Day, Location, Country)\n",
    "- Add Icons to photos (Flag of visited country, Map Marker)\n",
    "- Saves each photo in directory before compiling them in a video\n",
    "\n",
    "**Ideas:**\n",
    "- Find nice design for text and flag\n",
    "- calendar symbol instead of \"Day\"\n",
    "\n",
    "**TODOs:**\n",
    "- Get maximum one photo per day (maybe skip days with not so nice pictures)\n",
    "    - Find best frame within each photo\n",
    "- Make sure that fotos are ordered by date!\n",
    "\n",
    "**What text to show on each photo**\n",
    "- Day Counter\n",
    "- Date?\n",
    "- Location, Country (Flag, and/or Map?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cef4a5b-e38c-45b6-b576-a2e4cfa1c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # image and video processing\n",
    "import os # handling of filenames and directories\n",
    "import exifread # extract meta data from photos (date photo taken)\n",
    "import datetime # handling dates and days\n",
    "import re # for extracting date from filename\n",
    "import pandas as pd # for processing excel spread sheet with location info\n",
    "from PIL import Image, ImageDraw, ImageFont # for nicer fonts when adding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35006c3b-a72f-4108-a8a2-7282c62d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where pictures are stored\n",
    "input_dir = 'photos_dev' # folder with photos\n",
    "flag_dir = 'country_flags' # folder with png (transparent) photos of flags for each country visited \n",
    "output_dir = 'photos_processed' # output folder of rescaled photos\n",
    "outputtxt_dir = 'photos_text' # output folder of final photos with text\n",
    "\n",
    "# Check if output directories exit\n",
    "# if so, delete all jpg photos within directory\n",
    "# if not, create directory\n",
    "if os.path.exists(output_dir):\n",
    "    for file_name in os.listdir(output_dir):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            os.remove(os.path.join(output_dir, file_name))\n",
    "else:\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "if os.path.exists(outputtxt_dir):\n",
    "    for file_name in os.listdir(outputtxt_dir):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            os.remove(os.path.join(outputtxt_dir, file_name))\n",
    "else:\n",
    "    os.makedirs(outputtxt_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880d1cc1-b77d-473b-8618-4fe201753f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel spreadsheet\n",
    "# Format: Date,Day,location1,location2,height\n",
    "df = pd.read_excel('travel_data.xlsx')\n",
    "df = df.set_index('Day') # set Day as primary key\n",
    "df['Date'] = df['Date'].dt.date # convert dates to datetime\n",
    "start_date = datetime.date(2022,4,4) # Day counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1866a8-27fb-49cd-a6ba-ca07b69cfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video settings\n",
    "# video_sz = (1280, 720) # 720p\n",
    "video_sz = (1920, 1080) # 1080p\n",
    "video_name = 'output_video_v3.mp4'\n",
    "fps = 5.0 # frames per second\n",
    "photo_time = 1.5 # in seconds\n",
    "photo_frames = int(fps*photo_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58ad892-adf7-422e-a5fe-5d10db8d4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img, sz, ykeep = 0.5):\n",
    "    \"\"\"\n",
    "    Resize and crop or pad image to desired size\n",
    "\n",
    "    Args:\n",
    "        img: np.ndarray\n",
    "            input Image\n",
    "        sz: int tuple\n",
    "            desired size\n",
    "        ykeep: float\n",
    "            what part of image should be kept if being cropped\n",
    "            \n",
    "    Returns:\n",
    "        img: np.ndarray\n",
    "            resized Image\n",
    "    \"\"\"\n",
    "        \n",
    "    # shape of image\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Resizing the image to width by keeping aspect ratio\n",
    "    scale = width/sz[0]\n",
    "    height_new = int(height / scale)\n",
    "    dim_new = (sz[0],height_new)                \n",
    "    img = cv2.resize(img, dim_new)\n",
    "\n",
    "    # Check\n",
    "    # height, width, _ = img.shape\n",
    "    # print(f'resized: h={height} w={width}')\n",
    "\n",
    "    # Crop image on height (take the center)\n",
    "    if height_new>sz[1]:\n",
    "        \n",
    "        d = height_new - sz[1]\n",
    "        idx1 = int(d*ykeep)\n",
    "        idx2 = height_new-int((1-ykeep)*d)\n",
    "        diff = (idx2-idx1)-sz[1] # compensate for uneven pixel height\n",
    "        idx2 = idx2-diff\n",
    "        img = img[idx1:idx2, :] \n",
    "        \n",
    "        #height, width, _ = img.shape\n",
    "        #print(f'-> cropping: h={height} w={width}')\n",
    "\n",
    "    # Pad with zeros if image is height is too small\n",
    "    elif height_new<sz[1]: \n",
    "        diff = int((sz[1]-height_new)/2)\n",
    "        diff_corr = 2*diff+height_new-sz[1] # compensate for uneven pixel height\n",
    "        img = cv2.copyMakeBorder(img,diff,diff-diff_corr,0,0,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        #height, width, _ = img.shape\n",
    "        #print(f'-> zero-padding: h={height} w={width}')\n",
    "\n",
    "    # asseert that exported image size is of desired resolution\n",
    "    if img.shape[0] != sz[1]: \n",
    "        raise AssertionError(f'Height of image {img.shape[0]} does not match desired height {sz[1]}')\n",
    "    if img.shape[1] != sz[0]:\n",
    "        raise AssertionError(f'Width of image {img.shape[1]} does not match desired width {sz[0]}')\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a3c0ba-022e-4408-8ea0-6bd0cef6e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo_date(filename):\n",
    "    \"\"\"\n",
    "    Return date of image taken\n",
    "\n",
    "    TODO: if date cannot be extracted from photo or filename, catch error\n",
    "\n",
    "    Args:\n",
    "        filename: str\n",
    "            filename/to/image\n",
    "    Returns:\n",
    "        date: datetime.date\n",
    "            date of image taken\n",
    "    \"\"\"\n",
    "    # get meta information about image\n",
    "    with open(filename, 'rb') as f:\n",
    "        tags = exifread.process_file(f)\n",
    "        if 'EXIF DateTimeOriginal' in tags:\n",
    "            # extract the time the photo was taken\n",
    "            time_taken_str = tags['EXIF DateTimeOriginal'].printable\n",
    "            time_taken = datetime.datetime.strptime(time_taken_str, '%Y:%m:%d %H:%M:%S')\n",
    "            #print(f'{filename} was taken on {time_taken}')\n",
    "            #print(time_taken.strftime('%d/%m/%y'))\n",
    "            return time_taken.date()\n",
    "        else:\n",
    "            match = re.search(r'\\d{8}', filename)\n",
    "            date = datetime.datetime.strptime(match.group(), '%Y%m%d').date()\n",
    "            print(f'>> {filename} does not have a DateTimeOriginal tag. Automatically extracted date {date}')\n",
    "\n",
    "            return date\n",
    "        \n",
    "def extract_info(date,df):\n",
    "    \"\"\"\n",
    "    Extract meta information from excel spreadsheet of photo given date\n",
    "\n",
    "    Args:\n",
    "        date: datetime.date\n",
    "            Date of photo taken\n",
    "        df: pandas.core.frame.DataFrame\n",
    "            DataFrame table of travel locations\n",
    "    Returns:\n",
    "        country: str\n",
    "            name of country\n",
    "        loc: str\n",
    "            name of more precise location (e.g., closest city)\n",
    "        ykeep: float\n",
    "            what part of the image should be kept (if necessary)\n",
    "            0: keep upper part\n",
    "            1: keep bottom part\n",
    "            0<x<1: keep respective relative area (i.e., 0.5 keeps center of photo)\n",
    "    \"\"\"\n",
    "    idx_date = df['Date']==date\n",
    "    if sum(idx_date) != 1:\n",
    "        raise Exception('Date found less or more than once in excel spread sheet!')\n",
    "    country = df.loc[idx_date,'country'].values[0]\n",
    "    loc = df.loc[idx_date,'location1'].values[0]\n",
    "    ykeep = df.loc[idx_date,'height'].values[0]\n",
    "    \n",
    "    if ykeep<0 or ykeep>1:\n",
    "        raise Exception('ykeep is not bounded by [0 1]!')\n",
    "    \n",
    "    return country,loc,ykeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fab0af2-1c18-413d-b60a-7d08668924c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(img,text,xpos=10,ypos=10,fontScale=2,thickness=1):\n",
    "    \"\"\" [DEPRECATED] USES openCV function (cannot set Font)\n",
    "    Add text to image\n",
    "\n",
    "    Args:\n",
    "        img: np.ndarray\n",
    "            input Image\n",
    "        text: str\n",
    "            text to be added\n",
    "        xpos: int\n",
    "            x position of text\n",
    "        ypos: int\n",
    "            y position of text\n",
    "        fontScale: int\n",
    "            scale of text\n",
    "        thickness: int\n",
    "            thickness of text\n",
    "    Returns:\n",
    "        img: np.ndarray\n",
    "            Image with text\n",
    "    \"\"\"\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (xpos,ypos)\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = cv2.LINE_AA\n",
    "    \n",
    "    cv2.putText(img,text,bottomLeftCornerOfText, \n",
    "       font, fontScale, fontColor, thickness, lineType)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def add_text_PIL(file_name,input_dir,output_dir,text_large,text_small):\n",
    "    \"\"\" \n",
    "    Add text to image using Pillow Library (better due to more Fonts)\n",
    "\n",
    "    Args:\n",
    "        file_name: str\n",
    "            name of image\n",
    "        input_dir: str\n",
    "            directory  where image is located\n",
    "        output_dir: str\n",
    "            directory where image with text will be saved\n",
    "        text_large: str\n",
    "            large text to be displayed\n",
    "            here: \"Day XX\"\n",
    "        text_small: str\n",
    "            smaller text to be displayed (below text_large)\n",
    "            here: \"Location, Country\"\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filename = os.path.join(input_dir, file_name)\n",
    "    img = Image.open(filename)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    font_name = 'fonts/ShantellSans-Bold.ttf'\n",
    "    font_size = 100\n",
    "    font = ImageFont.truetype(font_name, font_size)\n",
    "    #draw.text((10,880),text_large,font=font,fill='rgb(255,255,255)',stroke_width=1,stroke_fill='rgb(0,0,0)')\n",
    "    draw.text((10,880),text_large,font=font,fill='rgb(255,255,255)')\n",
    "    font_name = 'fonts/ShantellSans-SemiBold.ttf'\n",
    "    font_size = 50\n",
    "    font = ImageFont.truetype(font_name, font_size)\n",
    "    draw.text((60,1000),text_small,font=font,fill='rgb(255,255,255)')\n",
    "\n",
    "    # save the image to the output directory\n",
    "    output_file = os.path.join(output_dir, file_name)\n",
    "    img.save(output_file)\n",
    "    print('AddedText: Saved ' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed045b27-8ade-4888-8683-c09938ce99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_scaled(filename,new_heigth):\n",
    "    \"\"\"\n",
    "    Get an image given desired height (keeps aspect ratio)\n",
    "    used for png images with transparent background\n",
    "\n",
    "    Args:\n",
    "        filename: str\n",
    "            location/of/image\n",
    "        new_heigth: int\n",
    "            desired heigth in pixels of image\n",
    "    Returns:\n",
    "        img: np.ndarray\n",
    "            rescaled image \n",
    "    \"\"\"\n",
    "    \n",
    "    # to load in png with additional alpha channel\n",
    "    img = cv2.imread(filename,cv2.IMREAD_UNCHANGED) \n",
    "    \n",
    "    if img is None:\n",
    "        raise Exception('Image ' + filename + ' not found')\n",
    "    \n",
    "    # shape of image\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    #print(f'old: {height} {width}')\n",
    "\n",
    "    # Resizing the image to width by keeping aspect ratio\n",
    "    scale = new_heigth/height\n",
    "    dim_new = (int(width*scale),new_heigth)                \n",
    "    img = cv2.resize(img, dim_new)\n",
    "    \n",
    "    #print(f'new: {img.shape[0]} {img.shape[1]}')\n",
    "    \n",
    "    return img\n",
    "\n",
    "def add_img(img_1,img_2,x_offset=50,y_offset=50):\n",
    "    \"\"\"\n",
    "    Add transparent image (png) to larger photo image\n",
    "\n",
    "    Args:\n",
    "        img_1: np.ndarray\n",
    "            image to be added, result of get_image_scaled\n",
    "            Note: alpha channel required in addition to its RGB channels\n",
    "        img_2: np.ndarray\n",
    "            photo to be overlaid by alpha img\n",
    "        x_offset: int\n",
    "            x location of img_alpha within img\n",
    "        y_offset: int\n",
    "            y location of img_alpha within img\n",
    "    Returns:\n",
    "        img: np.ndarray\n",
    "            photo with added img_alpha\n",
    "    \"\"\"\n",
    "\n",
    "    # add alpha image to photo\n",
    "    y1, y2 = y_offset, y_offset + img_1.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + img_1.shape[1]\n",
    "\n",
    "    # take care of transparent background\n",
    "    # combine both picture weighted by alpha values\n",
    "    alpha_1 = img_1[:, :, 3] / 255.0\n",
    "    alpha_2 = 1.0 - alpha_1\n",
    "\n",
    "    # Go through all channels\n",
    "    for c in range(0, 3):\n",
    "        img[y1:y2, x1:x2, c] = (alpha_1 * img_1[:, :, c] +\n",
    "                                  alpha_2 * img_2[y1:y2, x1:x2, c])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865d9daf-a9e8-4d5e-8005-e81fd2dcb054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Saved PXL_20220404_122730396.jpg\n",
      "AddedText: Saved PXL_20220404_122730396.jpg\n",
      "Processed: Saved PXL_20220405_133836774.jpg\n",
      "AddedText: Saved PXL_20220405_133836774.jpg\n",
      "Processed: Saved PXL_20220406_061928764.MP.jpg\n",
      "AddedText: Saved PXL_20220406_061928764.MP.jpg\n",
      "Processed: Saved PXL_20220407_113947773.jpg\n",
      "AddedText: Saved PXL_20220407_113947773.jpg\n",
      "Processed: Saved PXL_20220408_034225512.jpg\n",
      "AddedText: Saved PXL_20220408_034225512.jpg\n",
      "Processed: Saved PXL_20220409_093839860.jpg\n",
      "AddedText: Saved PXL_20220409_093839860.jpg\n",
      "Processed: Saved PXL_20220410_094057789.jpg\n",
      "AddedText: Saved PXL_20220410_094057789.jpg\n",
      "Processed: Saved PXL_20220411_082942412.jpg\n",
      "AddedText: Saved PXL_20220411_082942412.jpg\n",
      "Processed: Saved PXL_20220412_045052526.MP.jpg\n",
      "AddedText: Saved PXL_20220412_045052526.MP.jpg\n",
      "Processed: Saved PXL_20220413_051713537.jpg\n",
      "AddedText: Saved PXL_20220413_051713537.jpg\n",
      "Processed: Saved PXL_20220414_060135292.jpg\n",
      "AddedText: Saved PXL_20220414_060135292.jpg\n",
      "Processed: Saved PXL_20220415_040601404.jpg\n",
      "AddedText: Saved PXL_20220415_040601404.jpg\n",
      "Processed: Saved PXL_20220416_041257069.jpg\n",
      "AddedText: Saved PXL_20220416_041257069.jpg\n",
      "Processed: Saved PXL_20220417_060853938.jpg\n",
      "AddedText: Saved PXL_20220417_060853938.jpg\n",
      "Processed: Saved PXL_20220418_055314760.jpg\n",
      "AddedText: Saved PXL_20220418_055314760.jpg\n",
      "Processed: Saved PXL_20220419_044613581.jpg\n",
      "AddedText: Saved PXL_20220419_044613581.jpg\n",
      "Processed: Saved PXL_20220420_064531355.jpg\n",
      "AddedText: Saved PXL_20220420_064531355.jpg\n",
      "Processed: Saved PXL_20220421_061607742.jpg\n",
      "AddedText: Saved PXL_20220421_061607742.jpg\n",
      "Processed: Saved PXL_20220422_034951694.jpg\n",
      "AddedText: Saved PXL_20220422_034951694.jpg\n",
      "Processed: Saved PXL_20220423_054037289.PORTRAIT.jpg\n",
      "AddedText: Saved PXL_20220423_054037289.PORTRAIT.jpg\n",
      "Processed: Saved PXL_20220424_121652581.jpg\n",
      "AddedText: Saved PXL_20220424_121652581.jpg\n",
      "Processed: Saved PXL_20220425_114744022.jpg\n",
      "AddedText: Saved PXL_20220425_114744022.jpg\n",
      "Processed: Saved PXL_20220426_022128690.MP.jpg\n",
      "AddedText: Saved PXL_20220426_022128690.MP.jpg\n",
      ">> photos_dev\\PXL_20220427_092743878_exported_6919.jpg does not have a DateTimeOriginal tag. Automatically extracted date 2022-04-27\n",
      "Processed: Saved PXL_20220427_092743878_exported_6919.jpg\n",
      "AddedText: Saved PXL_20220427_092743878_exported_6919.jpg\n",
      "Processed: Saved PXL_20220429_131738265.MP.jpg\n",
      "AddedText: Saved PXL_20220429_131738265.MP.jpg\n",
      "Processed: Saved PXL_20220430_013312791.jpg\n",
      "AddedText: Saved PXL_20220430_013312791.jpg\n",
      "Processed: Saved PXL_20220502_143735957.jpg\n",
      "AddedText: Saved PXL_20220502_143735957.jpg\n"
     ]
    }
   ],
   "source": [
    "# Process Images\n",
    "# - go through each image in input directory\n",
    "# - resize and crop or pad image to video size\n",
    "# - extrat date of photo taken\n",
    "# - add text\n",
    "# - save transformed photo\n",
    "\n",
    "# get MapMarker\n",
    "mapmarker_img = get_image_scaled('resources/Map_marker.png',int(video_sz[1]*0.035))\n",
    "prev_date = start_date\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith('.jpg'):\n",
    "\n",
    "        # read the image\n",
    "        filename = os.path.join(input_dir, file_name)\n",
    "        \n",
    "        # get date when image was taken\n",
    "        curr_date = get_photo_date(filename)\n",
    "        \n",
    "        # check whether date is after date of previous photo\n",
    "        if prev_date>curr_date:\n",
    "            raise Exception('Photo ' + filename + ' date not sorted!')\n",
    "        \n",
    "        curr_day = (curr_date-start_date).days\n",
    "        prev_date = curr_date\n",
    "        \n",
    "        # get meta information about day from dataframe\n",
    "        country,loc,ykeep = extract_info(curr_date,df)\n",
    "                \n",
    "        # prepare image\n",
    "        img = cv2.imread(filename)\n",
    "        img = prepare_image(img, video_sz, ykeep)\n",
    "        \n",
    "        # get country flag\n",
    "        flag_img = get_image_scaled(os.path.join(flag_dir, country + '.png'),int(video_sz[1]*0.05))\n",
    "        \n",
    "        # Add country flag and MapMarker\n",
    "        img = add_img(flag_img,img,20,840)\n",
    "        img = add_img(mapmarker_img,img,20,1015)\n",
    "        \n",
    "        # save the image to the output directory\n",
    "        output_file = os.path.join(output_dir, file_name)\n",
    "        cv2.imwrite(output_file, img)\n",
    "        print('Processed: Saved ' + file_name)\n",
    "        \n",
    "        # Add Text\n",
    "        text_large = 'Day ' + str(curr_day)\n",
    "        if loc==country:\n",
    "            text_small = loc # Singapore show only city\n",
    "        else:\n",
    "            text_small = loc + ', ' + country\n",
    "        add_text_PIL(file_name,output_dir,outputtxt_dir,text_large,text_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3189de57-6e73-4347-b118-fdf47e6cceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making video ...\n",
      "Processing PXL_20220404_122730396.jpg ...\n",
      "Processing PXL_20220405_133836774.jpg ...\n",
      "Processing PXL_20220406_061928764.MP.jpg ...\n",
      "Processing PXL_20220407_113947773.jpg ...\n",
      "Processing PXL_20220408_034225512.jpg ...\n",
      "Processing PXL_20220409_093839860.jpg ...\n",
      "Processing PXL_20220410_094057789.jpg ...\n",
      "Processing PXL_20220411_082942412.jpg ...\n",
      "Processing PXL_20220412_045052526.MP.jpg ...\n",
      "Processing PXL_20220413_044028133.jpg ...\n",
      "Processing PXL_20220413_051713537.jpg ...\n",
      "Processing PXL_20220414_060135292.jpg ...\n",
      "Processing PXL_20220415_040601404.jpg ...\n",
      "Processing PXL_20220416_041257069.jpg ...\n",
      "Processing PXL_20220417_060853938.jpg ...\n",
      "Processing PXL_20220418_055314760.jpg ...\n",
      "Processing PXL_20220419_044613581.jpg ...\n",
      "Processing PXL_20220420_064531355.jpg ...\n",
      "Processing PXL_20220421_061607742.jpg ...\n",
      "Processing PXL_20220422_034951694.jpg ...\n",
      "Processing PXL_20220423_054037289.PORTRAIT.jpg ...\n",
      "Processing PXL_20220424_121652581.jpg ...\n",
      "Processing PXL_20220425_114744022.jpg ...\n",
      "Processing PXL_20220426_022128690.MP.jpg ...\n",
      "Processing PXL_20220427_092743878_exported_6919.jpg ...\n",
      "Processing PXL_20220429_131738265.MP.jpg ...\n",
      "Processing PXL_20220430_013312791.jpg ...\n",
      "Processing PXL_20220502_143735957.jpg ...\n",
      "Processing PXL_20220507_014636086.jpg ...\n",
      "Processing PXL_20220529_103425341.jpg ...\n",
      "Processing PXL_20220622_090823474.jpg ...\n",
      "Processing PXL_20220715_125153622.jpg ...\n",
      "Processing PXL_20220818_233800596.jpg ...\n",
      "Processing PXL_20220903_020654421.jpg ...\n",
      "Processing PXL_20221008_071546590 (1).jpg ...\n",
      "Processing PXL_20221021_214520238 (1).jpg ...\n",
      "Processing PXL_20221108_065532180.MP.jpg ...\n",
      "Processing PXL_20221120_021827616 (1).jpg ...\n",
      "Processing PXL_20221211_045320726.jpg ...\n",
      "Video done.\n"
     ]
    }
   ],
   "source": [
    "# Make Video\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(video_name, fourcc, fps, video_sz)\n",
    "\n",
    "# go through each image in input directory\n",
    "print('Making video ...')\n",
    "for file_name in os.listdir(outputtxt_dir):\n",
    "    if file_name.endswith('.jpg'):\n",
    "        img = cv2.imread(os.path.join(outputtxt_dir, file_name))\n",
    "        print(f'Processing {file_name} ...')\n",
    "        for i in range(photo_frames):\n",
    "            video_writer.write(img)\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "video_writer.release()\n",
    "print('Video done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
